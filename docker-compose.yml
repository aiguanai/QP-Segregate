services:
  # Local database services commented out - using cloud databases from .env
  # postgres:
  #   image: postgres:15
  #   environment:
  #     POSTGRES_DB: qpaper_ai
  #     POSTGRES_USER: qpaper_user
  #     POSTGRES_PASSWORD: qpaper_password
  #   volumes:
  #     - pgdata:/var/lib/postgresql/data
  #   ports:
  #     - "5432:5432"
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U qpaper_user -d qpaper_ai"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  # mongodb:
  #   image: mongo:6
  #   environment:
  #     MONGO_INITDB_ROOT_USERNAME: qpaper_user
  #     MONGO_INITDB_ROOT_PASSWORD: qpaper_password
  #   volumes:
  #     - mongodata:/data/db
  #   ports:
  #     - "27017:27017"
  #   healthcheck:
  #     test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  # redis:
  #   image: redis:7-alpine
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redisdata:/data
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - ./backend/.env  # Load all environment variables from .env file
    environment:
      # These will be loaded from .env file via env_file above
      - DATABASE_URL=${DATABASE_URL}
      - MONGODB_URL=${MONGODB_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
    volumes:
      - ./storage:/app/storage
      - ./tmp:/app/tmp
    # Removed depends_on since we're using cloud databases
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  celery_worker:
    build: ./backend
    env_file:
      - ./backend/.env  # Load all environment variables from .env file
    environment:
      # These will be loaded from .env file via env_file above
      - DATABASE_URL=${DATABASE_URL}
      - MONGODB_URL=${MONGODB_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
    volumes:
      - ./storage:/app/storage
      - ./tmp:/app/tmp
    # Removed depends_on since we're using cloud databases
    command: celery -A app.tasks.celery worker --loglevel=info

  celery_beat:
    build: ./backend
    env_file:
      - ./backend/.env  # Load all environment variables from .env file
    environment:
      # These will be loaded from .env file via env_file above
      - DATABASE_URL=${DATABASE_URL}
      - MONGODB_URL=${MONGODB_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
    volumes:
      - ./storage:/app/storage
      - ./tmp:/app/tmp
    # Removed depends_on since we're using cloud databases
    command: celery -A app.tasks.celery beat --loglevel=info

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    depends_on:
      - backend
    command: npm run dev

volumes:
  # Commented out since we're using cloud databases
  # pgdata:
  # mongodata:
  # redisdata:
